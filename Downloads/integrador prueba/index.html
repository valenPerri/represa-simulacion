<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Detecci√≥n de Manos en la Cabeza</title>
  <style>
    body { margin: 0; font-family: sans-serif; text-align: center; background: #111; color: #fff; }
    video, canvas { position: absolute; top: 0; left: 0; transform: scaleX(-1); }
    #mensaje { position: absolute; top: 20px; left: 50%; transform: translateX(-50%); background: #000a; padding: 10px 20px; border-radius: 8px; font-size: 24px; }
  </style>
</head>
<body>
  <div id="mensaje">Cargando modelo...</div>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <script type="module">
    import * as poseDetection from 'https://cdn.skypack.dev/@tensorflow-models/pose-detection';
    import '@tensorflow/tfjs-backend-webgl';

    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const mensaje = document.getElementById('mensaje');

    async function iniciarCamara() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      await new Promise(resolve => video.onloadedmetadata = resolve);
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    }

    function manosEnLaCabeza(keypoints) {
      const nariz = keypoints.find(k => k.name === 'nose');
      const manoIzq = keypoints.find(k => k.name === 'left_wrist');
      const manoDer = keypoints.find(k => k.name === 'right_wrist');
      if (nariz && manoIzq && manoDer) {
        const umbralY = nariz.y + 50;
        return manoIzq.y < umbralY && manoDer.y < umbralY;
      }
      return false;
    }

    async function iniciarDeteccion() {
      const detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet);
      mensaje.textContent = 'Detectando...';

      async function detectar() {
        const poses = await detector.estimatePoses(video);
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        if (poses.length > 0) {
          const keypoints = poses[0].keypoints;
          for (const kp of keypoints) {
            if (kp.score > 0.5) {
              ctx.beginPath();
              ctx.arc(kp.x, kp.y, 5, 0, 2 * Math.PI);
              ctx.fillStyle = 'red';
              ctx.fill();
            }
          }

          if (manosEnLaCabeza(keypoints)) {
            mensaje.textContent = 'üôå ¬°Manos en la cabeza!';
          } else {
            mensaje.textContent = 'üïµÔ∏è Manten√© tus manos sobre la cabeza';
          }
        } else {
          mensaje.textContent = 'Detectando...';
        }

        requestAnimationFrame(detectar);
      }

      detectar();
    }

    await iniciarCamara();
    await poseDetection.setBackend('webgl');
    await iniciarDeteccion();
  </script>
</body>
</html>
